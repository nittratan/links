import pandas as pd
import json
from transformers import pipeline
from tqdm import tqdm

# === Step 1: Load CSV ===
file_path = "results.csv"  # change if needed
df = pd.read_csv(file_path)

# === Step 2: Load Gemma 2 9B Instruct model ===
generator = pipeline(
    "text-generation",
    model="google/gemma-2-9b-it",
    torch_dtype="auto",
    device_map="auto",
    do_sample=False
)

# === Helper: Merge extracted JSONs ===
def merge_jsons(json_list):
    merged = {
        "Visit Reason": [],
        "Diagnosis": [],
        "Past Medical History": [],
        "Clinical Details": [],
        "Vital Signs": [],
        "Exam Results": [],
        "Lab Results": [],
        "Imaging Test Results": [],
        "Hospital and ED course": [],
        "Discharge Plan": [],
        "Full HPI": [],
        "Full Assessment and Plan": []
    }
    for js in json_list:
        for key in merged:
            if key in js and isinstance(js[key], list):
                merged[key].extend(js[key])
    for key in merged:
        seen = set()
        merged[key] = [x for x in merged[key] if not (x in seen or seen.add(x))]
    return merged

# === Helper: Extract info from one chunk ===
def extract_from_chunk(text):
    prompt = (
        "From the following medical text, extract the following sections and present them as JSON.\n"
        "Each section should be an array of strings, and each string should contain the extracted information "
        "along with a brief explanation in natural language where needed.\n\n"
        '{ "Visit Reason": [], '
        '"Diagnosis": [], '
        '"Past Medical History": [], '
        '"Clinical Details": [], '
        '"Vital Signs": [], '
        '"Exam Results": [], '
        '"Lab Results": [], '
        '"Imaging Test Results": [], '
        '"Hospital and ED course": [], '
        '"Discharge Plan": [], '
        '"Full HPI": [], '
        '"Full Assessment and Plan": [] }\n\n'
        f"Text: {text}\n"
        "Return the JSON now:"
    )
    output = generator(prompt, max_new_tokens=800)[0]['generated_text']

    try:
        json_start = output.find("{")
        json_end = output.rfind("}") + 1
        if json_start != -1 and json_end != -1:
            return json.loads(output[json_start:json_end])
    except:
        pass
    return {}

# === Step 3: Main extraction function with chunking ===
def extract_info_large(text, chunk_size=1500):
    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]
    results = []
    for chunk in chunks:
        js = extract_from_chunk(chunk)
        if js:
            results.append(js)
    merged = merge_jsons(results)
    return json.dumps(merged, ensure_ascii=False)

# === Step 4: Apply with progress bar ===
tqdm.pandas(desc="Processing rows (with chunking)")
df["google/gemma-2-9b-it"] = df["context"].progress_apply(extract_info_large)

# === Step 5: Save updated CSV ===
df.to_csv(file_path, index=False)
print(f"Processing complete. Updated file saved: {file_path}")
